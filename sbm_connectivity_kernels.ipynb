{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Stochastic Block Model Approach to Connectivity Kernels\n",
    "\n",
    "Previously, we saw how in the case of a categorical Blau space, the logistic connectivity kernel can be better represented as a stochastic block model (SBM), wherein nodes are members of a certain community $i \\in \\{1,2\\dots k\\}$ in the given Blau dimension, whose members form friendships according to a symmetric community-level probability matrix $\\Psi=\\{\\psi_{ij}\\}_{i,j=1}^n$.\n",
    "\n",
    "Let us consider a 1-dimensional categorical Blau space with $n$ people in $k$ communities. For each person $x_i \\in \\mathcal{X}$, we can write a corresponding membership vector $z_i \\in \\{0,1\\}^k$ containing exactly one $1$. (We could potentially relax this to mixed-membership vectors $z_i \\in [0,1]^k$ that sum to $1$.) Correspondingly, consider the assignment matrix $Z \\in \\{0,1\\}^{n\\times k}$. Then the stoachastic block model essentially suggests.\n",
    "\n",
    "$$A \\sim\\mathrm{Bernoulli}(Z\\Psi Z^T)$$\n",
    "\n",
    "Note that this can lead to self-loops, which we would not like to have in the graph. Let us write instead for the \"simple\" graph $\\hat{A}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mathbb{E}[A|Z,\\Psi] &= Z\\Psi Z^T \\\\\n",
    "\\mathbb{E}[\\hat{A}|A] &= \\mathbb{E}[A|Z,\\Psi] - \\mathrm{diag}(\\mathbb{E}[A|Z,\\Psi])\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "### Things to Note\n",
    "\n",
    "1. Clearly, the $\\mathrm{rank}(A) \\le \\mathrm{min}(\\mathrm{rank}(Z), \\mathrm{rank}(\\Psi))$, which implies $\\mathrm{rank}(A) \\le k$. This satisfies our intuition that the adjacency matrix of an SBM model probably has a basis of the order of number of communities, and not number of people. This means that we can effectively reduce problems concerning with the adjacency matrix down to the level of the probability matrix instead, as we attempt to do below.\n",
    "2. Since this is a probabilistic model, we will mostly talk of the expectation of the adjacency matrix below.\n",
    "\n",
    "## Eigenvalues and Eigenvectors\n",
    "\n",
    "Say we have somehow estimated the SBM matrix $\\Psi$, and are interested in the eigenspectrum of the corresponding adjacency matrix (more importantly perhaps the Laplacian matrix since it captures diffusion on the network). The above note suggests we should be able to do this at the level of $\\Psi$. Since $\\Psi$ and $A$ are both symmetric (we assume undirected networks), we already know they have real eigenvalues, and they can be eigendecomposed into a form given by $X=Q_{X}\\Lambda_{X}Q_{X}^T$ such that $\\Lambda_{X}$ is a diagonal matrix containing the eigenvalues of $X$, and $Q$ is an orthogonal matrix whose columns contain the corresponding eigenvectors. For notational convenience, we'll indicate $\\mathbb{E}[A|Z,\\Psi]$ simply as $A = Z\\Psi Z^T$. Now, corresponding to eigenvectors of $A$, we have the following:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "A v &= \\lambda v \\\\\n",
    "Z \\Psi Z^T v &= \\lambda v \\\\\n",
    "(Z^TZ)\\Psi Z^T v &= \\lambda Z^T v \\\\\n",
    "(D_Z\\Psi)(Z^Tv) &= \\lambda (Z^T v) \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the eigenvalues of $A$ correspond to eigenvalues of the product $D_Z\\Psi$, and the eigenvectors of $A$ correspond to $M_ZZ$ times the eigenvectors of the product $D_Z\\Psi$. Here, $D_Z$ refers to the $k\\times k$ community-count matrix $Z^TZ$ and $M_Z$ refers to inverse of the $n\\times n$ co-membership matrix $ZZ^T$. Clearly, if mixed-membership is not allowed, then $D_Z$ is a diagonal matrix. Moreover, if communities are equally represented, then $D_Z = (n/k)\\boldsymbol{\\mathrm{I}}$. Thus eigenvalues of $A$ are simply eigenvalues of $\\Psi$ scaled up by $n/k$.\n",
    "\n",
    "Alternatively, one can also write $\\Psi = D_Z^{-1}Z^TAZD_Z^{-1}$. Now, corresponding to eigenvectors of $\\Psi$, we have the following:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\Psi v &= \\lambda v \\\\\n",
    "D_Z^{-1}Z^TAZD_Z^{-1} v &= \\lambda v \\\\\n",
    "ZD_Z^{-2}Z^TAZD_Z^{-1} v &= \\lambda ZD_Z^{-1}v \\\\\n",
    "(Q_ZA)(ZD_Z^{-1} v) &= \\lambda (ZD_Z^{-1}v) \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the eigenvalues of $\\Psi$ correspond to eigenvalues of the product $Q_ZA$, and the eigenvectors of $\\Psi$ correspond to $Z^T$ times the eigenvectors of the product $Q_ZA$. Here, $Q_Z$ refers to the $n\\times n$ inverse-quadratically weighted co-membership matrix $ZD_Z^{-2}Z^T$.\n",
    "\n",
    "Clearly, if mixed-membership is not allowed, then $Q_Z$ is a block-diagonal matrix. Moreover, if communities are equally represented, then $Q_Z = (k/n)^2\\boldsymbol{\\mathrm{I}}\\otimes\\mathcal{I}_{n/k\\times n/k}$ and $A = \\Psi\\otimes\\mathcal{I}_{n/k\\times n/k}$, where $\\mathcal{I}_{n/k\\times n/k}$ is an all-ones or unit matrix of size $n/k\\times n/k$, assuming $n$ is a multiple of $k$ (since communities have same number of members). Then by using the mixed-product property of Kroenecker product we have $Q_ZA = (k/n)^2\\Psi\\otimes\\mathcal{I}_{n/k\\times n/k}^2 = (k/n)\\Psi\\otimes\\mathcal{I}_{n/k\\times n/k}$. Now, for the Kroenecker product $A\\otimes B$, let $\\lambda_1,\\dots, Î»_n$ be the eigenvalues of $A$ and $\\mu_1,\\dots, \\mu_m$ be those of $B$ (listed according to multiplicity), then the eigenvalues of $A\\otimes B$ are given by $\\lambda_i\\mu_j$ for $i\\in\\{1,\\dots n\\},j\\in\\{1,\\dots m\\}$. Now $\\mathcal{I}_{n/k\\times n/k}$ has eigenvalue $n/k$ with multiplicity 1 and rest $0$. Eigenvalues of $Q_ZA = (k/n)\\Psi\\otimes\\mathcal{I}_{n/k\\times n/k}$ are thus eigenvalues of $\\Psi$, scaled up by $n/k$ (due to the unit matrix), then scaled down by $k/n$. Hence, we obtain eigenvaues of $Q_ZA$ simply as eigenvalues of $\\Psi$, as expected.\n",
    "\n",
    "### For the Laplacian Matrix\n",
    "\n",
    "Similarly, it is straightforward to see how eigenvalues of $\\Psi$ get propagated to the Laplacian matrix. We define $L = D - \\hat{A}$, where D is the degree matrix of adjacency matrix $\\hat{A}$. (Since this is a probabilistic model, these are actually *expected* degree and Laplacian matrix.) Although we've been basing the discussion above on \"uncorrected\" $A$, we can straightforwardly define the Laplacian using just $A$ as $$L = \\mathrm{diag}(A\\boldsymbol{j}) - A$$ where $\\boldsymbol{j}$ is the unit vector. Pre and most multiplying by $Z^T$ and $Z$, we obtain $$Z^TLZ = Z^T\\mathrm{diag}(Z\\Psi Z^T\\boldsymbol{j})Z - D_Z\\Psi D_Z $$ Let $\\mathcal{L} = W_Z - D_Z\\Psi D_Z$ where $W_Z =Z^T\\mathrm{diag}(Z\\Psi Z^T\\boldsymbol{j})Z $ is a $k\\times k$ matrix that refers to the member-degree-weighted community-count matrix. Analogous to the relationship between $A$ and $\\Psi$, we have $$L = M_ZZ\\mathcal{L}Z^TM_Z$$. Since $M_Z$ is symmetric, we can write this as $$L = (M_ZZ)\\mathcal{L}(M_ZZ)^T$$\n",
    "\n",
    "We can now analogously repeat the analysis we did above.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "L v &= \\lambda v \\\\\n",
    "M_ZZ \\mathcal{L} Z^TM_Z v &= \\lambda v \\\\\n",
    "Z^TM_Z^2Z \\mathcal{L} Z^TM_Z v &= \\lambda Z^TM_Z v \\\\\n",
    "(R_Z\\mathcal{L})(Z^TM_Zv) &= \\lambda (Z^TM_Z v) \\\\\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Here $R_Z$ refers to the $k\\times k$ inverse-quadraticaly-weighted community-count matrix $Z^TM_Z^2Z$. The eigenvalues of $L$ correspond to eigenvalues of the product $R_Z\\mathcal{L}$, and the eigenvectors of $L$ correspond to $Z$ times the eigenvectors of the product $R_Z\\mathcal{L}$.\n",
    "\n",
    "Alternatively, we can express $\\mathcal{L} =Z^TLZ$ and figure that eigenvalues of $\\mathcal{L}$ correspond to eigenvalues of the product $M_Z^{-1}L$, and the eigenvectors of $\\mathcal{L}$ correspond to $D_Z^{-1}Z^T$ times the eigenvectors of the product $M_Z^{-1}L$. Clearly, if mixed-membership is not allowed, then $M_Z^{-1}$ is a block diagonal matrix. Moreover, if communities are equally represented, then using properties of the Kroenecker product it can be shown that eigenvalues of $L$ are simply eigenvalues of $\\mathcal{L}$ scaled down by $(k/n)^2$. Further, the expression of $\\mathcal{L}$ itself gets simplified to $$\\mathcal{L} = (n/k)^2(\\mathrm{diag}(\\Psi\\boldsymbol{j}) - \\Psi)$$ This leads to eigenvalues of $L$ being exactly the same as eigenvalues of $L_\\psi=\\mathrm{diag}(\\Psi\\boldsymbol{j}) - \\Psi$, where $L_\\Psi$ can be called the Laplacian of the SBM's probability matrix.\n",
    "\n",
    "## Back to a \"Simpler\" SBM\n",
    "\n",
    "The discussion above is for any general SBM model. To keep things simple, let us consider the SBM model described earlier, wherein essentially $\\Psi_{ii}=k\\rho\\omega$ and $\\Psi_{ij}=\\frac{1-\\rho}{1-1/k}\\omega$. (Recall that $k$ is number of communities, $\\rho$ is proportion of friends in same community, and $\\omega$ is the average edge density.) \n",
    "\n",
    "### Eigenvalues and Eigenvectors of Converse Connectivity Kernel\n",
    "Let us figure the eigenvalues and eigenvectors of the network described by this model. Let $Y$ be a symmetric matrix, and $\\alpha$, $\\beta$ be scalars.\n",
    "\n",
    "#### Claim: For symmetric matrix $X=\\alpha\\boldsymbol{\\mathrm{I}}+\\beta Y$ we have eigenvalues $\\Lambda_X=\\alpha\\boldsymbol{\\mathrm{I}}+\\beta\\Lambda_Y$ and eigenvectors $Q_Y$\n",
    "\n",
    "Proof:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "X &= \\alpha\\boldsymbol{\\mathrm{I}}+\\beta Y \\\\\n",
    "&= \\alpha Q_YQ_Y^T+\\beta Q_Y\\Lambda_YQ_Y^T \\\\\n",
    "&= Q_Y(\\alpha\\boldsymbol{\\mathrm{I}} + \\beta\\Lambda_Y)Q_Y^T \\\\\n",
    "&= Q_X\\Lambda_X Q_X^T\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Clearly, $\\Lambda_X$ is a diagonal matrix, and $Q_Y$ is orthogonal.\n",
    "\n",
    "Now for the SBM above we can write the probability matrix as $$\\Psi = \\omega\\left(\\frac{\\rho-\\frac{1}{k}}{\\frac{1}{k}\\left(1-\\frac{1}{k}\\right)}\\boldsymbol{\\mathrm{I}}+\\frac{1-\\rho}{1-\\frac{1}{k}}\\mathcal{I}\\right)$$\n",
    "\n",
    "Additionally for $\\mathcal{I}$ the eigenvalues are $k$ with multiplicity 1 and $0$ with multiplicity $k-1$. Using the claim above, eigenvalues of $\\Psi$ are given by $\\omega k$ with multiplicity $1$ and $\\omega\\frac{\\rho-\\frac{1}{k}}{\\frac{1}{k}\\left(1-\\frac{1}{k}\\right)}$ with multiplicity $k-1$.\n",
    "\n",
    "Let us assume that the \"test\" population, for whom we are evaluating the adjacency matrix, is also equiproportioned. Then we know eigenvalues of $A$ correspond to $n/k$ times eigenvalues of $\\Psi$: eigenvalues of $A$ are given by $\\omega n$ with multiplicity $1$ and $\\omega n \\frac{\\rho-\\frac{1}{k}}{1-\\frac{1}{k}}$ with multiplicity $k-1$.\n",
    "\n",
    "For $L_\\Psi$, under equiproportions, we get\n",
    "$$L_\\Psi = \\omega\\left(\\frac{1-\\rho}{\\frac{1}{k}\\left(1-\\frac{1}{k}\\right)}\\boldsymbol{\\mathrm{I}}-\\frac{1-\\rho}{1-\\frac{1}{k}}\\mathcal{I}\\right)$$\n",
    "\n",
    "Reusing the claim above, eigenvalues of $L_\\Psi$ and thus $L$ are given by $0$ with multiplicity $1$ and $\\omega\\frac{1-\\rho}{\\frac{1}{k}\\left(1-\\frac{1}{k}\\right)}$ with multiplicity $k-1$.\n",
    "\n",
    "#### Things To Note\n",
    "\n",
    "1. For $A$, the largest eigenvalue $\\mu_1$ is known to be related to the average degree of nodes $d_{avg}\\le\\mu_1\\le d_{max}$. We obtain this value as $\\omega n$, which is purely dependent only on the mean edge density $\\omega$, and is indeed exactly the the expected degree of a node (recall that $A$ can have self loops).\n",
    "2. The other eigenvalues of $A$ ($\\mu_2=\\dots...\\mu_k$) are positive for a homophilous kernel ($\\rho > 1/k$) and negative for a heterophilous kernel ($\\rho < 1/k$), and exactly zero for an ambiphilous kernel. But it can be shown that $\\forall\\rho\\in(0,1),\\forall k>1$, $|\\mu_k|<\\omega n$.\n",
    "3. It is [known](http://www.cs.yale.edu/homes/spielman/561/2012/lect03-12.pdf) if $A$ is a connected graph, then $\\mu_k=-\\mu_1$ if and only if A is bipartite. Clearly, a large negative $\\mu_k$ is only possible for a highly heterophilous kernel, which would mean people of a community almost always never connect to one another, which naturally lends a \"k-partite\" structure to the graph.\n",
    "4. Clearly, $0$ is always an eigenvalue of the Laplacian $L$.\n",
    "5. The spectral gap is same as the algebraic connectivity here and given by $\\omega\\frac{1-\\rho}{\\frac{1}{k}\\left(1-\\frac{1}{k}\\right)}$. Clearly, it is independent of the number of nodes in the graph, directly proportionate to mean edge density, and is always positive. Given a $k$, it is inversely proportionate to $\\rho$. Given a $\\rho$, it is directly proportionate to $k$.\n",
    "6. For an ambiphilous kernel ($\\rho=1/k$), the algebraic connectivity is equal to $\\omega k$. For a homophilous (heterophilous) kernel, it is less (more) than $\\omega k$.\n",
    "\n",
    "## Extending to Multiple Blau Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE; incorrect \n",
    "\n",
    "Let $Y$ be a symmetric matrix, and $D$ a positive diagonal matrix.\n",
    "\n",
    "#### Claim 1: For symmetric matrix $X=DYD$ we have $\\Lambda_X = D^2\\Lambda_Y$ and $Q_X = DQ_YD^{-1}$\n",
    "\n",
    "Proof:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "X &= DYD \\\\\n",
    "&=DQ_Y\\Lambda_YQ_Y^TD \\\\\n",
    "&=DQ_YD^{-1}D\\Lambda_YDD^{-1}Q_Y^TD \\\\\n",
    "&=(DQ_YD^{-1})D^2\\Lambda_Y(DQ_YD^{-1})^T \\\\\n",
    "&=Q_X\\Lambda_XQ_X^T\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "Clearly, $\\Lambda_X$ is a diagonal matrix, but $Q_X$ is NOT orthogonal :(\n",
    "\n",
    "#### Claim 2: For symmetric matrix $X=D\\pm Y$ we have $\\Lambda_X = D\\pm \\Lambda_Y$ and $Q_X = Q_Y$\n",
    "\n",
    "Proof:\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "X &= D \\pm Y \\\\\n",
    "&=D^{1/2}D^{1/2} \\pm D^{1/2}D^{-1/2}YD^{-1/2}D^{1/2} \\\\\n",
    "&=D^{1/2}(I \\pm D^{-1/2}YD^{-1/2})D^{1/2} \\\\\n",
    "&=D^{1/2}(I \\pm (D^{-1/2}Q_YD^{1/2})D^{-1}\\Lambda_Y(D^{-1/2}Q_YD^{1/2})^T)D^{1/2} \\quad\\quad \\text{(from claim 1)} \\\\\n",
    "&=D^{1/2}((D^{-1/2}Q_YD^{1/2})(D^{-1/2}Q_YD^{1/2})^T)D^{1/2} \\pm (D^{-1/2}Q_YD^{1/2})D^{-1}\\Lambda_Y(D^{-1/2}Q_YD^{1/2})^T)D^{1/2} \\\\\n",
    "&=Q_Y(D+\\Lambda_Y)Q_Y^T\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
